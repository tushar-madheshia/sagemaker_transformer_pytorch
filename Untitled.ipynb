{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc29689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/34/c2bcec634de677a7d05a868e72fd945bd40a2faf2ce249d773bd96c7eec2/boto3-1.28.46-py3-none-any.whl (135kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 7.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/31/b4/b9b800c45527aadd64d5b442f9b932b00648617eb5d63d2c7a6587b7cafc/jmespath-1.0.1-py3-none-any.whl\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/17/a3b666f5ef9543cfd3c661d39d1e193abb9649d0cfbbfee3cf3b51d5af02/s3transfer-0.6.2-py3-none-any.whl (79kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 3.9MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.32.0,>=1.31.46\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/2d/712e64154b563db350b666b50472d6df3c04e100c0ad4a4bfdc7dbd1e70e/botocore-1.31.46-py3-none-any.whl (11.2MB)\n",
      "\u001b[K     |████████████████████████████████| 11.2MB 21.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/05/c214b32d21c0b465506f95c4f28ccbcba15022e000b043b72b3df7728471/urllib3-1.26.16-py2.py3-none-any.whl (143kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 111.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil<3.0.0,>=2.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/7a/87837f39d0296e723bb9b62bbb257d0355c7f6128853c78955f57342a56d/python_dateutil-2.8.2-py2.py3-none-any.whl (247kB)\n",
      "\u001b[K     |████████████████████████████████| 256kB 91.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.5\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "\u001b[31mERROR: jupyterlab-server 2.24.0 has requirement babel>=2.10, but you'll have babel 2.9.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab-server 2.24.0 has requirement jsonschema>=4.17.3, but you'll have jsonschema 3.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: jmespath, urllib3, six, python-dateutil, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.28.46 botocore-1.31.46 jmespath-1.0.1 python-dateutil-2.8.2 s3transfer-0.6.2 six-1.16.0 urllib3-1.26.16\n"
     ]
    }
   ],
   "source": [
    "! pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c46778bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from refractml import *\n",
    "from refractml.constants import MLModelFlavours\n",
    "\n",
    "# new score functions\n",
    "from mosaic_utils.ai.score.base import ScoreBase\n",
    "from typing import Tuple, Union, List, Any\n",
    "import numpy as np\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac2d9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "bucket_name = \"sagemaker-us-east-1-123884475188\"\n",
    "object_name = \"huggingface-pytorch-training-2023-09-13-07-45-20-615/output/model.tar.gz\"\n",
    "file_name = \"/data/sagemaker/model.tar.gz\"\n",
    "\n",
    "s3 = boto3.client('s3',\n",
    "         aws_access_key_id=\"AKIARZWAXCM2FJGZ7LGJ\",\n",
    "         aws_secret_access_key= \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dced63ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3.create_bucket(Bucket=\"bucket-ame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab72b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bucket in s3.buckets.all():\n",
    "#     print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c55df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(bucket_name, object_name, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea3b5628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "! ls /data/sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d73019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "with tarfile.open(\"/data/sagemaker/model.tar.gz\", 'r') as tar:\n",
    "        tar.extractall(\"/data/sagemaker/HBS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65fa76c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-500\t   special_tokens_map.json  training_args.bin\r\n",
      "config.json\t   tokenizer.json\t    vocab.txt\r\n",
      "pytorch_model.bin  tokenizer_config.json\r\n"
     ]
    }
   ],
   "source": [
    "! ls /data/sagemaker/HBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d983f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/data/sagemaker/HBS\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/data/sagemaker/HBS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c0ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5d56780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 1.0577, -0.8930]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73832b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6f10d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0577, -0.8930]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43b8440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_id = logits.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "488db598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LABEL_0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7cb5b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreTemplateExample(ScoreBase): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\"/data/sagemaker/HBS\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"/data/sagemaker/HBS\")        \n",
    "    \n",
    "    def request_processing_fn(self, request) :\n",
    "        final_payload = []\n",
    "        raw_payload = request.json[\"payload\"]\n",
    "        return (1, raw_payload) \n",
    "    \n",
    "    def pre_processing_fn(self,payload):\n",
    "        # All preprocessing step must occur in this section\n",
    "        # Takes Single Sample -> Returns Single Sample\n",
    "        \n",
    "        # Not Doing Any Preprocessing Hence Returned payload\n",
    "        print(\"payload is \", payload)\n",
    "        \n",
    "        return payload\n",
    "\n",
    "    def prediction_fn(self,\n",
    "                      model: Any,\n",
    "                      pre_processed_input \n",
    "                      ):\n",
    "        encoded_input = self.tokenizer(pre_processed_input, return_tensors='pt')\n",
    "        output = model(**encoded_input)\n",
    "        logits = output.logits\n",
    "        predicted_class_id = logits.argmax().item()\n",
    "        class_pred = model.config.id2label[predicted_class_id]\n",
    "        return preds\n",
    "\n",
    "    class Meta:    \n",
    "        # List of Callables() can be attached For Calling After AnSd Before Scoring\n",
    "        def __init__(self):\n",
    "            self.name = \"Pre Hooked Me !\"\n",
    "            self.pre_call_hooks.append(self.print_)\n",
    "        def print_(self):\n",
    "            print(self.name)\n",
    "        pre_call_hooks = []\n",
    "        post_call_hooks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3573da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = ScoreTemplateExample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb4ec887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "req = requests.Request()\n",
    "\n",
    "req.json = {\"payload\":\"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39ad63ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre Hooked Me !\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALIDATION</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>PASSED</th>\n",
       "      <th>SKIPPED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Return Type Must Be Tuple (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuple Must Be of length Two (n_input, payloads)</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* if n_input &gt; 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])</td>\n",
       "      <td>request_processing_fn</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           VALIDATION  \\\n",
       "0                                       Return Type Must Be Tuple (n_input, payloads)   \n",
       "1                                     Tuple Must Be of length Two (n_input, payloads)   \n",
       "2  * if n_input > 1 payload type must be List (n_input, [np.ndarray, tf.Tensor, etc])   \n",
       "\n",
       "               COMPONENT  PASSED  SKIPPED  \n",
       "0  request_processing_fn    True    False  \n",
       "1  request_processing_fn    True    False  \n",
       "2  request_processing_fn    True    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields Marked Asterisk (*) Can Be Validated On Proper Input \n",
      "\n",
      "payload is  This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdry_run\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/mosaic_utils/ai/score/base.py:147\u001b[0m, in \u001b[0;36mScoreBase.score\u001b[0;34m(self, model, input_request, dry_run)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_with_schema_payload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meach_pre_processed_schema,\n\u001b[1;32m    144\u001b[0m                                      _clean_payload):\n\u001b[1;32m    145\u001b[0m     _clean_payload_validated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m _score_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_clean_payload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m _response \u001b[38;5;241m=\u001b[39m ScoreResponse(score_request\u001b[38;5;241m=\u001b[39minput_request\u001b[38;5;241m.\u001b[39mjson,\n\u001b[1;32m    150\u001b[0m                           request_processed_payload\u001b[38;5;241m=\u001b[39meach_request,\n\u001b[1;32m    151\u001b[0m                           rp_payload_validated\u001b[38;5;241m=\u001b[39m_rp_payload_validated,\n\u001b[1;32m    152\u001b[0m                           clean_payload\u001b[38;5;241m=\u001b[39m_clean_payload,\n\u001b[1;32m    153\u001b[0m                           clean_payload_validated\u001b[38;5;241m=\u001b[39m_clean_payload_validated,\n\u001b[1;32m    154\u001b[0m                           score_response\u001b[38;5;241m=\u001b[39m_score_response)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_response_collection\u001b[38;5;241m.\u001b[39mappend(_response)\n",
      "Cell \u001b[0;32mIn[22], line 27\u001b[0m, in \u001b[0;36mScoreTemplateExample.prediction_fn\u001b[0;34m(self, model, pre_processed_input)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprediction_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     23\u001b[0m                   model: Any,\n\u001b[1;32m     24\u001b[0m                   pre_processed_input \n\u001b[1;32m     25\u001b[0m                   ):\n\u001b[1;32m     26\u001b[0m     encoded_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(pre_processed_input, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoded_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     logits \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     29\u001b[0m     predicted_class_id \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "model_predictions = obj.score(None, req, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b0faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
